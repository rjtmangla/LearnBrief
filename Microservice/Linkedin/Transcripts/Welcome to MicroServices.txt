https://www.linkedin.com/learning/microservices-foundations-23469069?contextUrn=urn%3Ali%3AlyndaLearningPath%3A645bcd56498e6459e79b3c71&u=0
WelCome of Microserices:

History of service-based architectures
- We cannot have a discussionon "Modern Application Architectures,"without taking a brief look at where we have come from.When I started writing code professionally,end tier architectures, usually three tierand monolithic applications were the norm.We used to build a single binary web artifactand then decompose that application internally into layers.You would build a data access layerand then a process layer,and then on top of that, a presentation layer.Each of these layers would often then decomposeinto layers themselves, often in threes again,over and over.This layered architecture still gives me chillsdown my spine as I ponder the crazy pass through layersthat we would build just to satisfy the architecture.What we did get, however, was separation of concernsfrom the decomposition of our codeinto functional components.As monoliths continue to rule the environment,we started to see an anti-patternthat still hinders us today in many situations.The tight coupling of components in monolithsmake changes hard.And the older the application was,the more coupling would develop.In addition to the coupling issues,monolithic applications require considerable time to build,test, and deploy.The issues with monolithic applicationscompounded on top of itself as coupling caused code issues,which could only be fixed with long cyclesfrom code 'fix' to deploy, and the issues go on and on.We then saw a shift,and that shift was to service-based architectures,specifically SOA or service-oriented architecture.While these decomposed our applicationsinto smaller modules,it brought about several other issues.Now I will discuss the two that were most impactful to me.One, is the web service technology was based on SOAP,and while not a deal breaker in its own,it makes a lot of compromises that are contraryto how HTTP works.HTTP was designed with response codes,SOAP ignores these except for "OK",or "Internal Server Error."With SOAP, you get a 500 only,yet if the error is recoverable,you have to wrap it.The client then has to inspect the Unmarshaled XMLto see if the error is recoverable or not.The second and more prevalent issueis with the aggregation layer itself.While the aggregation layer can be written very thin,the reality is that not only do the transformationsof XML get added,but eventually Logic Operations started getting addedto the bus itself.This added a new level of coupling nowbetween internal and external elementsof the system as a whole.SOA was however the hottest architecture patternof the time.Enter into the picture microservices.Now, I would be the first to statethat microservices based architecturesare not the silver bullet.In fact, they bring their own sets of problems.They do however, have the promiseof a more agile frameworkthat can be extended into a cloud native world much easierthan either monolithic applicationsor SOA based architectures.The rage of microservices is not an accident either.The model fits well in both the web developerand web service developer, in partbecause HTTP is at the heart of the modelwhen rest is utilized.Now, some choose GraphQL or GRPC,and while they have the same issues that SOAP has,they do have benefits as well.As we begin to dig in, keep in mind the trade-offswe will take in microservices and use that to evaluateif this architecture pattern is for you.Now, we're going to dig into this pattern a little more deeplyso we can focus on the lessons of the pastto make for a better future.




The monolithic application
- Often when we discuss microservice architecture,the monolithic application is the primary target of our ire,which isn't always justified.Let's spend a moment and considerwhat is a monolithic application.Much of my experience with monolithcomes in two distinct flavors.The first and probably most prevalentfor me is large single file deployments.As a Java developer for much of my life,we used to package our deploymentsfor J2EE application servers using single files.All the components were builtand packaged into the common file structureand ultimately deployed as such.This packaging structure often has bothrelated and unrelated components.While we did encapsulate our work,that package would solve many uses,but the issue was not only the packaging,but also the deployment.A single deployment may contain internal data accesscomponents, business processes, web applications,web services, and even some remote procedure calls.All this packaged into one very large artifact.Now, the second issue looks at code usein a traditional monolithic application.Now, I often say as a profession, developers are lazy.If there's a shortcut, we take it.Now this isn't an indictment of our community.It's simply a statement of fact.If I can use an object designed for a purposeoutside of my use case,but shoehorned it into my use casewithout writing a lot of code, I usually will do it.It saves time and energy,often with little immediate side effects,but trust me, the side effects exist.That component or object now serves two masters.An enhancement or correction in that componenthas to solve the needs of both.Often, this causes us to handle very fragile codethat is so tightly coupled that getting outof the mess is next to impossible.So now that we've discussed the internal issues,let's look at how this can impact delivery.Let's say we need to make a changeto our highly coupled component.That change, assuming it is well tested,can pass all unit testsand still break unexpectedly downstream.So in order to deal with this,we must test the entire deployment as part of the release.That requires massive resources for every code chainsto just package the fix or enhancement.As such, we tend to group enhancementsand bug fixes into large scale releases packagedtogether, which of course impacts our speedto market of delivering a single business critical feature.Now, let's say we've handled the couplingin our code and handled the testingand packaging needs of our monolithic artifact.It's now time to deploy.I have seen and heard of deployments of monolithsthat can take days to accomplish,and then many more days of production validation.In the monolithic world,this pain is even more apparentif a feature coded in day oneof the cycle has been broken by the timewe get to the deployment stage,because now the whole cycle starts over again.Simply put, agility and maintainabilitysuffered dramatically in a monolithic world.Scalability is often impacted as well.Scaling out a monolith requires deployingthe entire package even if only one setof functions is under load.Considering the costs associatedwith monolithic deployments, as well as hardwareand other infrastructure costs,the monolithic application has lost a lotof favor in the development community.


Service-oriented architecture
- I want to start this conversation by stating thatI have spent a significant part of my professional careerwriting and consuming SOAP services,utilizing SOA platforms and, of course, service buses.So my biases come from my experience.I don't want to spend too much time on SOAP,but I do think it's important to discuss it some.SOAP, as a communication mechanism between systems,is not inherently bad.Like I just mentioned,I have done a lot of valuable work leveraging SOAP.I differ with the opinion of so many in the industryin that I don't feel XML is overly verbose.The verbosity of XML adds some validation valuethat in some places is very critical.Most of my criticisms about SOAPcome from how it was implemented,but more on that in a moment.SOAP's value, in my opinion, comes from its strong contract.There is no doubt in my mindthat WSDL is the single best part of SOAP.The definition language not only providesa strong contract that can be validated,but it also provides an inherent documentation layer.These benefits often get ignored when discussing SOAP,but it really aids business processing.The SOAP Envelope, in my view, is wasted space on the wirethat could have been handled in more efficient manners.My biggest issue with SOAP, however,is that everything is either OK or a 200 response,or a Fault, which is a 500 response.There is nothing in between.And in the real world,flow control requires much more granularitythan working or not.The promise of SOA,even with the deficiencies of SOAP, was amazing.Well-defined contracts of disparate systemscommunicating over a common protocol.The ability to build and deploy services and consume themthrough a simple contract was amazing.Many of the deployment issues with monolithswere solved with SOA, and we could simply do work.Once a service was built and deployed,then we would wire all the communicationsthrough standard business processing known as BPO.And here is where the real weaknessof SOA in my mind comes into play.The promise of business users wiring servicesonly worked in certain situations,and, even then, the work they were doing was abstractedfrom the web service's code.As BPOs got bigger, so did the coupling of the systems.The wiring became just as much part of the code baseas the traditional code did,and it was mostly hidden from the view of developers.The bloated systems became riddled with spaghetti code,painful deployments and fragile systems,all of which restricted agility.The industry noted these issues as well,and so its astronomic rise in usewas only matched by its crash.It really became easier to just manage the monoliththan to manage services and wiring in separate code basesalong with the costs associated with these systems.It just wasn't worth it in many people's eyes.



Microservices: The new kid on the block
- Microservices-based architecturesare really the new kid on the block,but they aren't babies.In fact, many of the concepts of microservices architecturecan be traced to core roots of SOAand other service-based architecture patterns.As with all patterns in software development,there is no silver bullet.And that is the themeof what we will discuss throughout this course.So, let's start the discussionwith the 50,000 foot view of what microservices means.At its core, microservices are about decomposingthe system into more discreet units of work.In my view, microservice developmentis about making the architecture at a component levelwork the way good development practices dowith modularization of the code itself.When we are taught how to solve problems in software,we're taught to decompose the problem into smaller problems,and then solve each of these problemsin a modular and decoupled fashion.Microservices simply takes this conceptand applies it to the system as a whole.There is no real size requirement on microservices.It's about building the servicesthe right size for the use cases.Microservices embraces the concept of protocol aware,heterogeneous interoperability to handle all communications.This means that every call within the service boundariesare solved via a common communication pattern.Most traditionally REST.This common communication allows microservicesto be implemented in a true polyglot fashionas long as the language provides some mechanismfor creating, responding to, and executingagainst the common communication endpoints.Microservices are just as much about the communicationas the services themselves.In a pure microservices architecture,each unit of work can be calledfrom any other unit of work within the system.This ability to call any serviceprovides a lot of flexibility,but can also lead to headaches.And often, hybrid architecturesare leveraged to solve these concerns.This architectural pattern has really gainedincredible popularity in both the traditional enterprise,as well as startup communities,and it has done so for a good reason.SOA was expensive to implement and get off the ground.Microservices, however, are cheap.In fact, the entire execution and proxy environmentcan be done entirely with open-source softwareon commodity hardware.Even if you choose to build a cloud native platformto execute your services in,you can do this entirely as open-source,again, on commodity hardware.The more you dig into this pattern,the more power you will see in leveraging OSS,and not just in the code itself.After all, there is no better experiencethan learning from both the mistakes,as well as the successes of your peers.We did see this level of hotness before with SOA,but it really only applied to enterprise shopsfor the most part.But that excitement quickly fizzled out.Whereas with microservices, so far it hasn't.While there are many reasons for this,I believe agility and the abilityto distribute these systems globallyare the biggest reasons why the level of interest continues.As we go through this course,we will focus on the positives that this pattern brings,but we must temper our excitement someas we're also going to look at the costsassociated with moving to this pattern.



Microservices: Solver of problems but not the silver bullet
- Every architecture decisionthat is made ultimately comes down to compromises.There is no single silver bulletthat solves every use case you have,and even within a pattern, there are compromisesthat need to be made.As I previously alluded to, there are costs to payfor moving to microservices architecture,and I feel it is critical to discuss these somebefore we dig into the pattern.You and your organization must decideif the benefits you gain from moving to microservicesis worth the cost you pay.No matter how hot this pattern is,if it isn't right for you, don't force it.One of the biggest costs you will pay,especially early in the process, is complexity.In a monolithic system, you have oneor maybe a few components to managethose components may be large, but if your processesand procedures require a lotof gates in the software life cycle,microservices architectures will dramatically cost you timeand money as you move from a few deployed artifacts to many.In addition to the deployment complexity, determiningwhere all of the code livesand operates in a microservices architecturecan increase the complexityand the costs associated with it.If your churn to production is not a simple caseof packaging and deployment,but instead a complicated process, walk lightlywith microservicesunless you are willing to update your process.Now, if I were the architect consulting your organizationand you were dealing with a complex set of processesand gates around deployments,I would investigate those stepsand determine how much of it can be automatedand how much of it can be trimmed.I don't want to make it sound like a complex process shouldlimit microservices development.You just need to take it into account.Another cost you paywith microservices is the so-called distribution tax.As you build a microservices architecture out,there is a dramatic increase in network communicationsbetween the individual services.This increases the total latency of calls across the networkas a whole.In addition to individual calls taking more time fromthe client perspective, the increase in call volumetends to risk congestion,causing catastrophic latency across the network as a whole.A single slow call in the stackcan cause thread blocking that impacts other clients.Often you see teams move to reactive technologiesto alleviate the single-threaded blocking calls.However, the distribution tax still persists.Another similar problem is the reduction of reliability.This is one area where technologies can dramatically help,but as you put more moving parts into a system,there is a decrease in the overall reliabilityof the system as a whole.If one microservices is sick, the impact canand often does extend to multiple client calls.It becomes criticalto evaluate your most core servicesand determine if they can withstand system unreliability.Again, there are ways to build your systemto be more reliable,but if you cannot foresee the system working in a partialstate of availability, you may needto evaluate if microservices are the right pattern for you.Ultimately, as we progress through this course,I will continue to point outwhere these risks come into play.Your ability to make decisions that maximize benefitwhile reducing risksand complications will help spell successfor your organization,but making blind decisions will risk failure.Throughout the rest of this course,as I bring up the potential pitfallsof this architecture pattern, my intention is notto discourage you from moving this direction,but instead to arm you with the knowledge neededto make the correct compromises that will leadto success.


Microservices and cloud native
- Often when we talk about microservices,we're talking about cloud native,but that isn't always the case.It's important for us to level seton what the two have in common and what they don't.Cloud native architectures are based looselyon building applications according to the 12 factoror 15 factor methodologies.If you aren't familiar with this concept,please take a look at my course on 12 factorand 15 factor cloud native applications.This current course focuses on microservicesand not cloud native, but often they do go together.So let's spend a few minutesand discuss this at a high level.Cloud native architectures include patternsfor designing systems to run in cloud-based infrastructure.Now, cloud infrastructure is a very loose term.Often when people hear cloud, they assume AWS or Azure,but that's only part of the story.Cloud infrastructures can be public,but they can also be private or even hybrid.Cloud computing is a patternof globally distributing systemsto provide increased uptime, increased scalability,and increased distribution.You can build cloud native systemsthat run in a single data centerwith plans on building out more globally,or you can build systems that run in a public cloudthat can be further distributed when needed.Microservices tend to fit very nicelyinto a cloud native architecture because they tendto very easily transition into that pattern.But I do want to be clearthat they are two very distinct concepts.You can build monolithic cloud native applications,and you can also build microservices that are not capableof moving to the cloud at all.I hear all too often people confusing the two patterns.To be honest, that concerns me.We must keep the delineation clear so as notto confuse the topics,which is why I am spending this much time discussing itin this course.For all of their differences,as I've said, they do tend to go together.In my professional life,every microservice we build today is aimed at deliveringto a cloud native platform.We started our microservices journeybefore our cloud journey, but the two have quickly merged.Let's a look at where they fit together.A microservice-based application is usually storedin a single code base, which is a requirement for 12 factor.A microservice oftenis also a completely self-contained unitmaking the move to the cloud much easier.Usually, there are only a few changesin how dependencies are managedand the leveraging of backing services, bothof which come naturally in a microservices model.One of the biggest challenges is workingwith the file systems.These use cases usually require a migrationto something like Amazon S3or some other remote file system.Throughout the rest of this course,I will be focused solely on microservices,but as I just mentioned, in my professional life,we deploy our microservices to a cloud native platform.I will try to share tidbits of informationthat will help you make this transition from VMor big iron based microservices to a cloud native version.But again, our primary focusis indeed the microservices themselves.


Microserice core Concept
The services
- One of the first questions I am always askedwhen discussing microservicesis what makes a microservice just that?And it's a compound answer.I want to start by stressing that it isn't as muchabout the size of the service,but the operation of the service that really matters.There isn't a finite requirement on size.Before we get into the size question, however,let me answer one of the easiest parts of the question,and that is how the services communicate.In a microservices architecture,all communication between services utilize HTTP,most often REST, though some people use GRPC,and often frontends will consume GraphQL.There are other methods like event-based communications.However, the interest service calls are all over HTTP.This is a powerful proposition,especially for large organizations.Consider a company the size of Amazon or Netflix.Both of these companiesutilize microservices-based architectures.Each of their teams can build software as they see fitif the services are exposed via HTTP.Each team can then consume the services of another teambecause they all communicate in a common way.One thing to note:Unification of service documentation is often ignoredand shouldn't be.Along with documentation is service discovery,but we'll talk more about that one later on.So let's return to our size conversation.In a microservices world,size isn't as critical as operations.A microservice handles one set of related functionswith little or no cross-domain operations.This is where concepts like domain-driven designcome into play,and we will spend a significant amount of timetalking about domains in a little bit.I like to use the analogyof good object-oriented programming practiceswhen describing microservices.In a well-defined OOP space,a class is built to handle one type of thingand provide all of the operations for that type.In a microservices architecture,a service operates on a well-defined domain.Operations aren't defined on data objectsor business objects.Instead, it's the domain as a whole.Now, you can, and probably should,provide very low level, data-focused servicesin a microservices architecture.Often, these specific servicesexpose domain-specific crud operations on the domain object,but that domain can span multiple data objects.You can also build a serviceto handle a set of related business processesthat may span one or more domains.So the answer to the size question isn't size.It's that a domain-focused operation is what matters.In my opinion, this is one of the hardest parts to learn.All too often when a companyor team moves into a microservices architecture,they build their services either too fine-grainedor conversely, not fine-grained enough.Usually, it's the former.This is a common occurrence,and quickly the distribution tax will hit you hardas the latency of calls really kicks in.As you start building these services,don't be afraid to refactor.And my hope is that by the end of this course,you'll be more willing to experiment.The ability to experiment comes in partfrom the size of these services.Yes, size isn't part of the answer,but logic will tell youthat as you start decomposing these services down,they become smaller and smaller.Smaller services build faster, have fewer test scenarios,deploy quicker and start up much quicker.All of these aid in the willingness to experimentand make mistakesbecause you can fix those mistakes much fasterin smaller components of code.


The communication dance
- In a microservices architecture,the interservice communications can be a sourceof freedom for growth,but it can also be a source of great pain.I want to spend a little time looking at the network trafficthat takes place in a microservices-based systemand focus on some of these potential pains.All communication between individual servicesin a microservices architecture is over HTTP.I will focus on REST as that is my preferred method.This communication framework allows any serviceto be developed using any coding languageor framework that supports RESTful services.Each service can consume any other serviceover the same communication strategy.This strategy, as previously mentioned,is called protocol-aware heterogeneous interoperability.In a nutshell, this explains that the servicesare bound to a protocol, in this case, HTTP,and execute communication over that protocol in a waythat works in a mixed or heterogeneous environment.This has a lot of power when we get down to it.The development team is often composed of developerswith many different skill sets.You may have backend developers workingin Java or Go, for instance.You may have front end developers workingin JavaScript frameworks like React.You may also have data scientists working in Python.The beauty of a microservices architecture isthat each team member can build the servicesin a language native to them,and then expose those services for othersto consume using HTTP.Other teams that need to consume these servicesneed to have zero knowledgeof how the services themselves work,nor do they needto learn some special communication technology.They simply leverage HTTP the same waythat they would if they were calling their own services.This emphasizes one of the primary problemsthis architecture tries to solve,and that is agility.The agility of this model comes from each team workingin a language and framework that is natural to them.They can deliver code quicklybecause they aren't constrainedby artificial boundaries imposed by the rulesof the architecture pattern.Every modern framework, for instance, can leverage REST.The same cannot be saidfor communication protocols like SOAP.As the teams work in their own domainas efficiently as possible, they deliver code quicker.Once the code is delivered,they expose the contractso others can consume the services just as quicklybecause there is no learning curve.Now this communications dance does come with problems.We're going to spend some time talking about them in depthas they can quickly sour the system as a whole.But for now, we will simply acknowledge that they exist.In this model, at least in its purest form,each service is capableof calling any other service in the system.There are no constraints on who can call what,which means orchestration is key.Each service must maintain a certain levelof passivity in their APIs,or there's a risk of system failure.Because any service can call any other service,there is no clear delineation of who may be calling you.You must either have a solid versioning strategyor maintain perfectly passive APIsto prevent calling systems from failingwhen you release a new version of your API.In a monolithic system,breaking API changes are usually more apparentthan in a microservices architecture.So you need to stay focused on this issue from day one.I recommend a solid versioning strategy, contract testing,and strong passivity rulesto prevent this from becominga major concern in your system.Ultimately, enhance your knowledge of this dance,and you will be much more equippedto handle the issues when they do arise.

Distribution and scale
- The communication pattern of microserviceslends itself to a truly distributed model.While global distribution is not a requirementfor a microservices architecture,the possibility is one of the benefitsof this model as a whole.Along with the ability to distribute your system,the microservices architecture modelprovides for a highly-scalable system.Both of these properties are very powerfulfor a modern application suite,but as usual, with software, they also come with a price.Let's start by discussing distribution.Each service is accessed over remote network callsregardless of being in a local or remote data center.Therefore, you can theoretically move you servicesanywhere you want around the globeand the system would work.Now, from a reality perspective,putting services all over the world is costly,both in infrastructure,but also in the latency of the calls themselves.The benefit of this ability, however,shouldn't be lost on the individual service-to-service call.Microservices distributionsolves the problem of getting infrastructureand services globally available when neededwithout making your entire system globally available.Look at this model from the enterprise perspective.You may have customer facing applications and servicesthat need to be regionallyor globally distributed to support high-availabilityor geospatial needs,but you may also have a set of applicationsand services that are solely enterprise focused.These lines often get blurred as your business growsand you expand your operations,so building out a system of microservicescapable of global distribution from day oneprepares your enterprise for the future.Likewise, the ability to scaleis part of this architectural style.In a microservices architecture,each service is independent of every other serviceor application in the system.As such, when an individual service comes under load,it can be individually scaled.So let's take a quick look at how this scaling works.Consider a microservice that serves customer data.This is a well-defined domainthat handles all of the requeststhroughout your system for this type of data.Now, imagine that your companyreleases the hottest new productand you start seeing a large numberof new customers interacting with your system.Therefore, your customer servicestarts taking on a significant load.Now, in a traditional model,you would have to scale every component of your systemto handle the load increases on that single service.A microservices architecture, however, allows you to simplyincrease the number of instances of your customer servicewhen you were experiencing that load.Now, assuming that you're using a solid API proxy layer,which we will discuss,your system will have zero changes neededoutside the increased count of your customer service.Now here we're talking about horizontal scaling,but vertical scaling also works as well.To experience the real power of this scaling model.Consider how you plan your infrastructure today.Traditionally, you build your system planningfor your busiest day.In a well-defined microservices architecture,with the right platform,you can build your system for an average dayand allow scalability to solve for the increasesor the decreases in traffic volume.This so-called elastic scalability,it's very hard, if not impossible,for a monolithic application.Now, I mentioned that all of this comes with a price,and in the next video we'll discuss some of the costs.But I do want to stress that these two topics,scalability and distribution, are some of the most valuable,if not the most valuable benefits of this architecture.which we will discuss later,your system will have zero changes neededoutside the increased instance countof your customer service.Now here we're talking about horizontal scaling,but vertical scaling works as well.To experience the real power of this scaling model,consider how you plan your infrastructure today.Traditionally, you build your system planningfor your busiest dayin a well-defined microservices architecture,with the right platform,you can build your system for an average dayand allow scalability to solve for the increasesor the decreases in traffic volume.This so-called elastic scalability,it's very hard, if not impossible,for a monolithic application.Now, I mentioned that all of this comes with a price,and in the next video, we'll discuss some of the costs,but I do want to stress that these two topics,scalability and distribution, are some of the most valuable,if not the most valuable benefits of this architecture.



The dangers of latency and gridlock
- The communication pattern of a microservices architectureimproves the ability to scale and distribute your system,but it comes with cost.Blindly moving into this without acknowledging these costsand working to mitigate themcan cause a catastrophic failure.Every service invocationin a microservices architecture is a remote network call.As such, there is connection set up, tear down,and wire latency on every single call.This latency is relatively insignificant for a single call,but as the code path becomes more and more complex,that single call can become many.In addition to the latency increasesof the calls themselves,as the traffic increasesand services come more under load,the risk of latency in response time increases.In a system based on remote invocation of all service calls,any latency added to the normal flow can be detrimentalto the system as a whole.Latency in a low-level serviceor any service for that mattercan become exponentially exaggerated in a modelwhere every call is remote.At a certain point,this latency can develop into gridlock.While calls are waiting for responses,delays can become unbearable.When this occurs,there can be a catastrophic failure of the entire system.Another path to gridlock can arise due to circular calls.In a pure microservices architecture,any service can call any other service.This call stack can become circularwhen a calling service is subsequently calledby what it's calling.When this occurs,latency can become a problem much more quicklyas multiple services can depend on a service involvedin this circular call stack.When deciding to move to a microservices architecture,you must spend a significant amount of time evaluatinghow to control the negative reactions to latencyand not just gridlock.One such pattern is to use a circuit breakerwithin your code.In this pattern,you build a standard flow through your application,and when latency rears its ugly headand timeouts start occurring,you trip the circuitand execute a default behaviorthat doesn't invoke the troubled service.While you may sufferfrom a reduced functionality of your system,it's often better to do thisthan to suffer a complete failure.Now, when the services are back to normal,the circuit closes,and the normal operation through your systems returns.Netflix, for instance, released Hystrixas an implementation of this patternto support their offerings.If search is down, for instance,the platform should still be able to allow usersto view movies.By offering such a pattern within their software,the web applicationor the mobile applications can still function,even if search doesn't,as this degraded level of performanceis ultimately the desired state.Now, you don't have to implement a circuit breakerto solve for latency issues,but at the very least,you need a strong timeout logic throughout your systemto prevent gridlock from crippling the system as a whole.Strong timeouts, global distributionof all service offerings,scaling of individual services under load,and leveraging patterns like circuit breakerwill help alleviate the issues when they do occur.Again, knowledge of these benefitsand risks is key to success.



Bounded context
- When deciding how to size your microservices,one common strategy is to leverage domain-driven design.And as such, to focus on the bounded contextwhen decomposing a large multi-domain systeminto individual services.Understanding how to properly decompose an applicationfor a microservices implementation is not an easy task,and this design pattern can help you.The core concept is to investigate your working systemand determine the domains,then focus on the boundaries of those domains,as well as the inner workings of them.Use that knowledge to break your services up.Most of the early mistakes in migrating an existing monolithinto a microservices architecturecomes from either making your services too granularor not granular enough.The key to finding the sweet spot on granularityis to leverage domain-driven design,but to do so in an educated manner first.So let's talk about determining the bounded contextfor your domains.The gut reaction may be to just break your data domains upand focus on that alone,but you run the real risk of having latency creep upwhen you do this.You really need to spend some time,and analyze the traffic patternsin your code based on real-world use cases.Telemetry is a great tool to help with this.Once you identify the actual use cases of your system,then you can start evaluating the interaction boundaries.Part of the goal in building on your bounded contextis to reduce your crossed domain calls where appropriate.Say, for instance, you have a customer domainthat is fairly well-defined,but you also have a user domain for your login information.As you look at traffic patterns,you note that every time your user domain is called,it calls your customer domain.Now, this would be an argument for putting bothof these domains into a single-bounded context,but you may need to investigate just a little deeper.What if there were only 1%of the calls from your customer domainwere from your user domain, and at the same time,there is data in your user domain that needsto be secured in a different manner?These may be sufficient argumentsto separate them into different bounded contexts.There is no clear-cut pattern here,but once again, knowledge is key.So you may have a feeling about why bounded context mattersat this point, and if you're guessing latency, that's right.Latency is such a pain point in microservices.There's frankly no need to add extra callswhen they make zero sense.By evaluating the domainsand building strong bounded contexts,you can reduce the numberof calls made in your system as a whole.By reducing the distribution tax on your system,you will have better overall system health, which, in turn,will make your microservices implementation more successful.One other reason to have strong definitionsof the bounded contextis for better contracts between services.With well-defined boundaries of your context,you get a self-discovery of your system as a whole.Because you have taken the time to build out these domainsand structure them precisely,a consumer of a service on your system should be ableto determine the correct location to search for the servicesthat they need to consume.So while this process is aimed at improving performanceof the system as a whole, it can also improve your agilityand speed of your development processes,which, ultimately, is what every team strives for.


Data domains as a service boundary
- Previously, we talked about bounded contextsand leveraging domain driven designfor appropriate boundaries on microservices in general.When it gets to the data access layer itself,the so-called data services,things get a little different at times.In the data layer, you have to take more into accountthan simply the bounded context of your domainbecause now, you have to deal with data transactions.We're going to talk about base versus acid later on,but one of the hardest changes,especially for larger enterprise systems,is removing the transactional boundariesin an existing database.It isn't easy to just stop doing operations transactionally,and if you think you can just leveragedistributed transactions to solve these problemsin a microservices architecture, stop now.Stick with your monolith.As I promise you,this will be nothing but pain for you and your team.Again, we're going to talk about this more later,but it is important to understand this place is a constrainton the design decision for data domains.Building data domains for low level servicesis one of the hardest parts ofa microservices architecture for various reasons.This usually is because it involves decomposinga monolithic database into smaller individual systems.Now, there are a couple of different waysof tackling this problem, and we're going to talk about both.The first strategy is to simply startwith the database itselfand break it up into smaller databases,and then build the associated services.Now, while this may yield a quicker result,it tends to put you in a bind if you make a mistake.If you are well-versed in your system utilization,it can be a quicker path, so it really depends onwhat you know and how well you know it.Migrating data is significantly harder in a live systemthan building services, especially if you leveragean API layer on top of those services.This brings us to the secondand more recommended pattern of building your data domains,and that is to start with the servicesinstead of the database.By starting with the servicesand having them all connect to the monolithic database,you'll start to see if your domains are well-defined.You can see the traffic flows across the networkand leverage that knowledgeto start modeling your data itself.The overall objectiveis to minimize the cross-domain calls where possible,enforce your needed transaction boundaries,and then you can start decomposing your databasesinto smaller instances.Building strong data domains is criticalto a solid microservices architecture.Most, if not all operations through the systemwill touch one or more data domains.They can become a large source of painif you don't take the time upfront to solidify them.A good telemetry and tracing pattern cannot be ignoredas a viable tool to utilize when you're doing this work.Take your time with these componentsand ensure you focus on the most efficient operationsthroughout your system.You'll thank me later.


No ACID, only BASE
- Let me start by sayingI have done distributed transactions professionally,and not only were they painful to get right,they were also extremely hard to manage.I do understand the desire, especially in a SOA model,to drive for distributed transactions.But this really should be considered a non-starterin a microservices architecture.Traditional systems aimedfor transactions that were ACID compliant.ACID, or atomic, consistent, isolated, and durable,is the concept of making sure that you have data integrityacross multiple tables in a traditional relational database.An atomic operation is one that has the propertiesof either succeeding completely or failing completelywith no gray area in between.A consistent operationis one that guarantees all of the constraintsor data model rules will be enforced.An isolated operation is one in which the visibility rulesare well-definedsuch that no other transaction can read datathat is not in the correct state.A durable operation is one that, once completed,will be guaranteed to be in the data store permanentlyuntil it is modified in the future.These properties work beautifullyin a monolithic applicationwhere there is no distribution.In a SOA model, they become painful.In a microservices model, they are close to impossible.In a microservices architecture,we often strive for BASE, or basically available,instead of ACID.In a BASE model,we strive for eventual consistencyacross the highly available distributed platform,which is the exact use case a microservices architectureaims to work in.In this eventual consistency model,we are not guaranteed immediate, atomic,or isolated consistent transactions.Instead, we aim for a situationwhere, assuming the data isn't modified again,we will achieve the end statein all of the nodes across our distributed data store.ACID is, in all honesty,a much easier paradigm to work in as a developeror as an architect.You know that when you read or write datathat you are guaranteed of its stateby the underlying data store.This guarantee allows you complete controlof how to handle high throughput systemswhere data changes occur oftenand must be immediately available.In a microservices architecture,you need to identify where you truly need asset transactionsand wrap service boundaries around those operations.You cannot leverage any other modelwith any real success in this type of architecture.But before you just go out and make everything transactionaland create a system of monoliths,I urge you to evaluate if you really need ACID transactions.More often than not,you may find that what people perceiveas a need for immediacyis instead just an unnatural expectation.We often expectthat users need immediate access to the data,when in reality, they never view the data immediately,and we can solve the same use caseby directing them to some other placeif they really need to view that data.Now, as I mentioned,there are times when you do really need ACID transactions.Take a moment and consider a banking system.When you perform a balance transfer, for instance,you have a credit to one account and a debit from anotherthat must occur in a single transaction.In these use cases,you will need to model your domains and servicesto continue to allow these transactions to be atomic.But there may be other places, say applying for a loan,that already have some level of asynchronous operation.These can benefit from eventual consistency model.Now, there are ways to design a systemfor eventual consistency,including appropriate rollbacksthat will help you in this process.And while we discuss some of the tenets of these designs,it really is outside the scope of this course.There are plenty of good materials onlineand other resources availablewhen you're ready to tackle these problemsin the real world.Aim for eventual consistency in as many places as possible,and it will improve your system health as a whole.


The API layer
- An API layer is often includedwith microservices architectures, and for a good reason.In a pure microservices architecture,an API layer is nothing more than an aggregated proxyof all of your service offerings.The API layer is used to shield the outside worldor even your clients from knowing the structure,organization,or even what exact service is exposing a specific operation,which is actually very useful.The API layer provides a standardized proxy interfacethat will expose whatever service endpointsand API operationswe configure it to expose.We need to be careful herethat we aren't transforming the APIs.There's a better way to do that for, say,a mobile client versus a desktop client.The API layer, in my opinion,is a pure proxy.Consider our use cases around scalingup our system under load,orscaling down under a lull.If our service consumption model is one in which we arebound directly to the hosts,managing this infrastructure can become painful,especially across multiple data centers.Now, there are some service discovery toolsthat will aid in this process,but in my opinion,these are really nothing more than a synthetic API layer.In this scaling model,the API layer isolates the clientfrom needing to know the direct IP addressand port of the service it's calling.From the API layer, we're calling hundredsof different endpoints without really knowing which serviceproduces the endpoint itself.Let's consider another use case,and that is isolation from change.Regardless of refactoring a monolithor building out new service offerings,if our first step is to implement an API layer,clients will have minimal, if any,changes to make in response to underlying refactoringof the code base itself.If every service is exposed through an API proxy layer,you can break the services up,or aggregate themand simply have the proxy configuration changeto match the development operations.The clients will not be impacted, period,unless of course you make a breaking change,which of course, you should avoid at all costs,and maybe consider leveraging versioning.An API layer can also assist you in versioning operations.Now, I'm not going to be prescriptive about howto handle version changes in your systembecause there's more than one valid way,butyour API layer can help youby directing to a legacy version of a servicewithout forcing a client to make changes,even if the deployment model itselfchanges.While the API layer is usually denotedas being completely optional,I find that it's one of the most crucial componentsif you want to reduce the overall impact of movingto this architectural model.So as such, please consider it.


Microserice advanced Concepts:
Asynchronous communications
- One of the best strategies for dealingwith reducing latency on a microservices based system isto not rely on a purely synchronous communication model.Leveraging event-driven asynchronous communicationsis a fantastic way to improve system health as wellas support long-term objectives of moving large amountsof data over long distances in a fairly timely fashion.Asynchronous communications, however, are not easy.You need to put significant work into ensuringthat your communications reach their destinationand are processed in accordancewith predetermined tolerances.Learning how to appropriately handle and respondto air conditions is critical to keeping the system running.Most often when you hear mentionsof asynchronous communicationsin a microservices architecture,people are specifically referringto event-driven microservices as a wayto support eventual consistency of the data.In this model, the services put a messageinto an asynchronous message brokeror a temporary data store,and then drive events from this state change.The downstream event processors will process the dataand eventually cause the datato be stored in its final data store.Mutations will then occurthrough either distributed data patterns,or subsequent event processing.While this model is the most common one discussed,it is definitely not the only one.Stream data platforms are a very strong patternwhen building out a large system,especially with many different but interesting operations.In a stream data platform, events are writtento a central message broker.These events then trigger listener operationsthat take action on the data if it applies to them.These events can trigger operationsthat format the data, cause other downstream events,or various other activities.These stream data platforms, in my experience,can be highly useful in large distributed systemsbecause often, events trigger multiple operations,not just one.By leveraging a platform like this, you can do more workwith less overall stress on the system,which of course improves overall performance,especially in activities like logging, auditing,security, or other data inspections.One of the most overlooked patternsin this space is the transitionfrom pure synchronous operations to asynchronous processing.We are impatient by nature,and we seem to always want systemsthat have immediate feedback,but it is not always needed.Many times, we can simply defer the processingto occur in an asynchronous manner.When we do this, we reduce the latency constraintson the functions that are requiredto be executed in real time.Part of the goal of movingto asynchronous operations is load reduction,but as I mentioned, it isn't always just a simple move.When moving to asynchronous operations,you need to take care to handle error states correctlyand recover from them.If messages cannot be processed for any reason,you cannot simply ignore them.Dead letter queues must be monitoredand action must be taken to process the messages,even if the remediation is manual.Data should be routinely monitored for correctnessin an automated fashion,and performance must be evaluated to ensurethat the message brokers are not getting behind.Now, I encourage you take some timein your system design and investigatehow leveraging asynchronous communications can helpyour team achieve reduced latency and increase throughput.


Logging and tracing in a microservices architecture
- One of the hardest operational problemsto solve in a microservices architecture is evaluatingcall chains and aggregating logging associatedto those call chains.When an issue arises in a microservices architecture,it can become very difficult to see all of the moving parts,especially when you considerthat your calls span multiple virtual machinesor containers, many with their own sessions.The good news is that solving these problemscan be relatively straightforward, but you need to planfor this observability early in your design process.A unified approach early on in the processwill prevent serious reworkonce you realize the value of these principlesin your overall architecture,I would strongly recommend you take this advice seriouslyand plan for unification on these topicsacross your entire organization.We will start our discussion with logging.You will find that having unified loggingthroughout your system will be criticalin not only evaluating the day-to-day operationsof your system, but also in troubleshooting,maintenance, investigations, and other general tasks.The issue of logging, however, becomes significantly noisierin a microservices environment.Part of the issue is simply the larger volumeof artifacts in the system,but also because of the agile naturethat is bred from this architecture,you often have various functional teamsbuilding different services.As such, each of these teams may end up developingdifferent logging strategies,as well as formatting of those logs.While the lack of unificationof log data may not seem like a big deal,the reality is that as you move to a distributed system,there's an increased need to havesome sort of convergence in your logging behaviors.As the system size grows,you may find yourself moving from traditionalfile system-based logging to log aggregators.These log aggregators make uniformitythat much more critical so that you can scanand coalesce them more easily.Part of making logging more powerfulin a distributed environment is the ability to determinethe actual flow, not only through your service,but through the system as a whole.There is a solution for this problem,and it's often called tracing.Tracing is based on the conceptof creating a unique token called a traceand using that trace in all internal logging eventsfor that call stack.By embedding this value in the loggingand timing output, each service uses the traceand then passes it downstreamto all of the service calls it makes.Each of those in turn do the same.There are several different strategiesfor moving the trace ID from service to service,but the important part isthat the trace ID exists in all of the log messagesfor all services throughout the systemfor a given call stack.By leveraging this strategy, you can aggregate a setof log messages, as well as timings,when looking at metrics and behavior.Determining the behavior from a single user interactionthrough a system in a microservices architectureis hard, but tracing makes this problem much simpler.If you structure your log messages in a unified mannerand include the trace,you will see a huge benefit when the need does arise.


Continuous delivery as a requirement
- When building out a microservices architecture,one of the goals is agility of your development teams.As your system grows in size,maintaining the agilityof your team in all aspects of developmentcan become a challenge.We all know that writing code is only one aspectof the software development lifecycleand while smaller artifacts make deployment easier,deployments can become a nightmare.As a rule of thumb,you need to invest time in building outa continuous delivery modelearly in the process.Microservices based architectures have so many moving partsthat the chances of success greatly decreaseif you don't have an automated way of buildingand deploying these services.So let's take a look at what it meansto build out a CI/CD,or continuous integration and continuous delivery pipeline.A CI/CD pipeline starts with the most basic aspectsof building your committed code basein an automated fashion building.Your code can be as simple as executing a scriptthat manages the build cycle itself,or as complex as a large distributed modelof containerization and sandbox build operations.The build step compilesand often executes unit tests to ensurethat the code is ready for further testing and deployment.Once the build step has completed,we often add a stepof automated deployment to a non-production environment.This automated deployment step moves the compiled artifactto a runtime that often mimics productionbut does not take production traffic.In this environment,we often run integration and system tests,as well as security-focused penetration tests.These tests should provide a clear indication of the safetyof moving the code to production.Doing this while automating as muchas possible will help breed success.So while there may be manual gates within the process,the end goal is automation.When the code has been sufficiently validated,it will be deployed to production.Once the code is in production,we can use routing techniques like blue-green deploymentsto push production traffic to our new code.Obviously, this is the overall goal of the process,but in order to make it most effective,each and every opportunity to automatea task should be taken.Now you may wonder why I statethat this process should be considered as a requirement.As previously mentioned,one of the goals of microservices is agility.If you build microservicesbut don't do the automation around delivery,there is no real improvement in agility.When you look at the development process as a whole,agility is such a strong improvement in this space.You owe it to yourselfand your team to make this a priority.When moving to microservices, start small.Focus on building, deploying and basic testing,and then expand from there.Consider adding integration into your ticketing system,your chat system, and other testing frameworks.Advanced automation include things like self registering,your deployment with monitoring and routing systems,and this should be your long-term visionto maximize the value to your teamwith respect to agility.



Hybrid architectures: Hierarchy and service-based
- A pure microservices architecture can be to many teams,a very daunting task.In addition to the work comprised of movingto this architecture, the "unknown unknown", so to speak,can be hard to wrap into a roadmap.In addition to this, there are some really hard problemsto solve, like database segmentationand service boundaries that in the untrained eyeof your customers, may have no real tangible value.As such, there are concrete steps you can takein the interim to gain some of the benefitsof a microservices architecturewithout going fully into the matrix.One of my favorite hybrid architectures in this spaceis a hierarchical service model.While many thought leaders in the industry will stronglyadvise against this,because of the dynamics around team coupling that can occur,it does prevent some of the risksof circular dependencies in the network, whichas we have discussed, can bring a system to its knees.In a hierarchical microservices architecture,you define rules about which service types canor cannot consume other service types.One common pattern here is based on the old N-tier modeland is the one that I have had the most success with,especially during the migration of a monolithto a microservices model.In the N-tier hierarchy model,you may define a few different classes of services.One common class is the data servicesthat expose data domain specific logic completelyto the outside world.Another common class is the business process servicesthat specify high level business processesthat are well-defined.You may also create gateway services that build abstractionsto external dependencies.Another possibility is you may define edge servicesthat expose your dataand business processes to the outside world.These are just a few examples of the types of servicesthat you may define.Once you have a clear taxonomy built about what tasks eachof these services do, you can then startto build out rules about which classof service can be consumed by other service classes.You may want to look at the risks of a circular call treeand make a rule that no data servicecan consume another data servicewithout being involved in a business process.Now, this complex set of rules may,at face value, seem like an easy way to prevent issues.The reality is that they come with risks.Often, you have to adjust your logicand flow through the systemto accommodate your artificially imposed rules.You may find yourself buildingand defining business processesthat don't really exist in orderto play nice in your own sandbox.Sometimes to the point of simple pass through services,which do nothing but at artificial latency.Take this hybrid model and its risks seriously,even if you just consider doing it as a transition method.Another very common architectureis the so-called service-based architecture.In my mind, this is very similarto the SOA model in which you leave the underlying databasesalone and simply carve out your services.By migrating your architecture to this service-based flow,you can gain some of the agility improvementsof the microservices model without sharding your datainto separate data stores.Again, while this hybrid modelhas some value, take it lightly.This does start your journey to microservicesand is a great starting point,but it can also lead to the so-called monolith of monoliths.When your service offering extendsbeyond the original scope,because you don't have well-defined domains,you end up hurting yourself in the long run.There are many other hybrid models you can see patternby leading companies or even in your own mind,and while they may solve some issues, they probably comewith some baggage as well.Consider all the benefits and risks of any modelbefore diving in head first.Make sure you can manage the risksand maximize your rewards.



Making Architectures CHoices:
Design considerations
- When starting the process of designing your microservices,there are a few key points to considerbefore you write a single line of code.While I have mentioned most of this already,I want to roll it up into a clear concise picture,and explain how your designs should accountfor this material from the ground floor.One of the first aspects you should consider when designingmicroservices is your continuous integrationand continuous delivery pipelines.Don't write any code until you have a planon how you will handle these tasks.In my opinion, it is such an important conceptin microservices architecture that it honestlyshould be task number one, model a sample pipeline,and ensure you have the most critical stepsof your SDLC documented and automated, if possible.Secondly, consider spending some real time designingyour logging, tracing, and telemetry frameworks.This should really be a primary function of every service,so the code required to do this work should bein a common library for every artifact to consume.Consider how you will aggregate and evaluate your logsand metrics and design your code to solve that need.Consider the use of log aggregatorsand search mechanisms for those logs early onso you can structure the data appropriately.Now, as it gets to your service code,you really should consider leveraging domain-driven design.You need to do some real analysis on the system as a whole,and use that knowledge to help you defineyour service boundaries.Adding telemetry to your existing offeringscan help you with this.Consider how you will build your servicesand what functions they will perform.Will you leverage dedicated data services,or wrap the data access into business processes?Should you consider moving services together to allowfor asset transactions where you need them,or will you build out a strategybased on eventual consistency?As you build out these services,plan for designing mechanisms to evaluateand eventually control your latency.Evaluate the use of non-blocking code when possible,but consider standardizing your stackno matter which way you go.I know many developers may not like to hearthe word standardize, but the reality is that the mostsuccessful teams when moving into a microservicesarchitecture have standards across the code base.You can leverage a different standardthan you currently use, but standardization will allow youto shift resources much more easilyas the business needs change.I also encourage you to design your systemto be asynchronous first.By that, I mean try to create every serviceas an asynchronous operation until you provethat you need it synchronously.This is probably contrary to how you are currentlydoing things, but having a solid plan for asynchronousactivity will not only reduce latency on your systemas a whole, but will allow you to improve your skillson these operations while reducing error rates.Designing a microservices architecture is less aboutthe code and more about the supporting processes,operations, and infrastructure.


The tradeoffs
- I have said it many timesthat building a microservices architectureis not a silver bullet when it comes to developing software.I have also spent a significant amount of our timetalking about what the issuesthat can arise in this model are.I want to talk about these from the perspective of comparingand contrasting the trade-offs.Many thought leaders in the communityhave significant documentation on these trade-offs,so I'm just going to apply some of my personal experiencesto the information that I have gathered from them.We have talked a lot about the distribution tax.There's a significant costof building out a distributed system,but you get several benefits from this.One of the biggest benefitsis well-defined module boundaries.It is a lot harder to write tightly coupled codewhen you have to go across the service boundaryto make a call.In addition, you get a much easier pathof scaling your system.These are real trade-offs that you need to manage,and they may be some of the most critical in the system.We have talked a lot about this and various solutions,like event-driven asynchronous patterns,because they are so critical.Think about a company like Amazonthat clearly does business globallyand has spikes in order activityaround Christmas, for instance.And for them to manage their systemin a monolithic deployment,it would be next to impossible.They have managed the cost of distributionin order to leverage a clear benefitof doing business globallyand under a highly available model.One of the other dichotomies to evaluate in microservicesis deployment complexity.We have discussed the ability to scalein this architectural style.However, that ability to scaleincreases the complexity of our deployments.Now, I would argue that deploymentsare always a hard part of software delivery.But in microservices,there are just so many more moving partsthat the complexity increases dramatically.We've also talked about ways to solve this complexitythrough continuous delivery.The benefits of scaleand reducing the waste associated with it can be measured.The final trade off that I will talk aboutis the ability to have diversity in your technology stack.We talked about microservices being a heterogeneous model,but this ability to write your services in any technologycomes with real operational costs.You can fully embrace polyglot development if you want to,but managing these services in productionwhen they follow different rules can be a huge challenge.From my experiences,it is often better in these casesto embrace a smaller set of technologiesto improve your ability to manage the operations.I have said this several times as well,but you have to spend some serious timeevaluating these trade-offs within your system.Play to your strengthsand control your weaknesses,and you will achieve significantly better results.I really hope that I'm imparting in youa real need to plan and not just jump in.

An argument for edge services
- If you remember when we discussed SOA,the beep layer allowed youto expose various services over a common bus.This bus brought about significant problemsin managing your codeas often it became bloated with code itselfand that bloat decrease the abilityto manage the infrastructure.In a microservices architecture,you often leverage an API proxyto hide your service implementations behind a common layer.But again, this layer can become bloatedif you start transforming your service offeringsbased on client needs,which is a common approach many are tempted to take.With all of this,you may ask how you can solve multiple client needswhich brings us to edge services.The really are two distinct types of edge servicesin my view,and we will talk about them separately.The first and most common is the outbound edge service.These services are usedto expose your client's specific needs to the outside world.The other edge service,often called inbound or translation services,are more important to me in that they are designedto abstract you from third party dependencies.Let's talk about the inbound edge services first.Think for a momentabout the third party systems you contract withand imagine how often those contracts change.I want to talk about a real use caseand that is an email marketing scenario.Your company most likely leverages a third party send systemto handle outgoing email communicationsso you don't trash your internal email system.Sometimes, these communications are transactionallike an order fulfillment or a status notification.But sometimes these communications are marketing based.Either way, you will have some set of contentand you will leverage these systemsto simply handle the SMTP operations.When you consume these services,you can either call the APIs directlyor build an edge service that you ownto interact with a third party.If you build the abstraction layer or edge service,you control the impact of vendor API changesin a single placebut also provide yourself a path for vendor replacementif the need arises.And hey, most likely it will.After all, technology and pricing changes like crazy.When you build an abstraction layer like this,you minimize the impact of changeswhich is critical to the health of your system as a whole.Imagine a breaking API change from the vendor.Now you can roll that change out to one serviceor hundreds of them.I prefer the single service.It is true that you have now introduced one more hopin every call to the remote service,but you can manage that through asynchronous operationsespecially on a service like email sending.Even if you cannot manage the latencythrough asynchronous operations,the reduction of code changes alone makes this a benefit.Now let's talk about the outbound edge services use case.Not every client that consumes your serviceneeds the same data payload.Mobile scenarios tend to thrive on smaller payloads of data.But you need a place to manage this.You could manage it through your proxy layeror through an API gateway.But I hope at this point you see the potential risks.If however, you manage client specific edge servicesand simply proxy them,you get several key benefits.The first is that you are managing the transformationsin code that is similarto all of the other code in your system.This immediately makes managing this code much easier.You also gain another key benefit.Think back a few videos agowhen I talked about how critical it wasto make your API changes passive or to leverage versioning.This is even more critical for your clientsespecially those that you cannot immediately updatelike mobile or desktop clients.By building out edge services,you can continue to provide them a consistent interfaceeven if the underlying services change.Designing your servicesso they're isolated from changes cannot be underestimated.Spend a little extra effort when designingand coding for these use casesand you will reap the rewards downstream.


Embracing DevOps
- Throughout this course,we've talked a lot about managing trade-offsin a microservices architecture.I have talked about the various improvements to a systemthat can be achieved through microservicesas well as the potential impacts.I've also talked about the operational costsand the need to build out a continuous delivery model.All of what we have discussed boils down to one major thing,culture.The single most effective wayto be successful in a microservices architectureis to build it into your culture.A DevOps culture is a perfect fitfor building out a microservices architecturebecause the two complement each other's strengthswhile mitigating the weaknesses.DevOps aims to bring the conversation between operationsand development into the same sphere.It is from this perspective that we will spend some time.I've talked a lot about increased operational complexityfor a microservices architecture, from the distribution taxto increased deployment counts for a system.Most of the issues from microservices can be seenas operational issues.The distribution tax in a microservices architecture is onethat must be closely monitored to ensurethat lag in the system doesn't have major impacts.There are several architectural mitigationswe have discussed.But regardless of the mitigations,monitoring the system remains the most important aspect.A platform of continuous monitoring and automated responsesbecomes a necessity for operations.DevOps aims to leverage automationand embed the work into the development function.We spent a significant amount of timetalking about common logging and tracing for a reason.They lead to a simpler use case for automated monitoring.Once we have the data and have it structuredin a unified and well-defined format,we can write code to respond in an automated fashion.Consider increased response timesor increased 500 response codes triggering repavingof the infrastructure, or at the very least, a pager call.By automating these routines, your culture will drive waysto make these automated responses even more efficient,which in turn gives you better responses to system events.Consider also the complexityof deployments in a microservices architecture.Managing the deployment and releasesof code manually becomes impossible in this style.Again, we discussed CI/CD as a requirementof microservices, for a reason.Automation of deployments and testingimproves the agility of the team.The operational events that are manualin a traditional model are improved with automation,which in turn provides more throughputfor the team, as a whole.Ultimately, much of what we has discussedin this course, has been about culture.We want to maximize the positives like scaling, agility,or the ability to globally distribute our system.To do that, we have to automate.We also need to mitigate the latencyand complexity of deployments as well.Once again, to do that, we have to automate.The DevOps culture breedsa more successful microservices platform,and a more successful platformbreeds a deeper DevOps culture.They go hand in hand for a reason.So don't fight it, embrace it.in this course, has been about culture.We want to maximize the positives like scaling, agility,and the ability to globally distribute our system.To do that, we have to automate.We also need to mitigate the latencyand complexity of deployments as well.Once again, to do that, we have to automate.The DevOps culture breedsa more successful microservices platform,and a more successful platformbreeds a deeper DevOps culture.They go hand in hand for a reason.So don't fight it, embrace it.


Monolithic microservices
- Not every single use case is ready for microservices.In fact, many times, especially in early-stage startups,the concept of microservicesis just too much for the small team to deal with.There are, however, very specific steps you can taketo prepare a monolith earlyfor an eventual breakup as needed.Let's start with the planand then get into the arguments for this.The basic idea behind the monolithic microserviceis to ensure you are using all of the strategieswe have discussed at this point,with the exception of breaking the components up.So, what does that really mean?Well, if we start at the lowest point,we build out our data services in a waythat they can be broken apart in the future.We focus on domainsand expose those domains with solid APIs.In doing this, extracting these domains lateris significantly easier.You can even take this a step furtherand build your database schemas in a waythat you can easily break your databases up as well.We are talking about domain-driven design still,but keeping the APIs hidden from the outside world.You can continue this pattern up to your presentation layeras you see fit.I highly recommend that you encapsulateas many of these potential services as possible.You may not need them all,but you still have built highly testable componentswithin your application,and that is always a good thing.The biggest argument I've seen when working in this spaceis you have such a large unknown unknownearly in a startup's journey.You can spend energy building outa complex microservices architecture,or can keep the end vision in mind,but focus your energy on product-market fitby delivering real features.The key here is keeping a scalableand distributable system in mindat every step of the way,which helps you break it up if you need to.Another big argument for doing this modelis, simply, you don't have the staffearly on in your journey,nor do you need it.While your application is small, as well as your team,the added complexity of microservices to gain agilityis kind of a moot point.Your team is small,so they should be agile enough in a monolithic codebase.In addition, the application is small,so building and deploying it is significantly easier.Now, it still is important to consider the future.You should use solid CI/CD.You should be focusing on solid encapsulation.But in the end, you can do all of these in a monolith,in a way that you can break it apart in the future.In the end, building out microservicesstarts with solid principles,and building monoliths still benefit from these principles.Good observability, solid APIs and UIs,solid encapsulation, CI/CD,and everything else we have discussedworks to your advantage with any system you build.But as your system gains popularity and use,you will reap rewards by focusing on these key principles,because adding scalability to your systemis so much easier when it was designed that way.Don't feel like there's only one answerwhen building these systems,monolith or microservice-based.